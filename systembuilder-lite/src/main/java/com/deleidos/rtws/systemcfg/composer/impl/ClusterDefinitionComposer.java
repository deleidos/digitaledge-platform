/**
 *                                  Apache License
 *                            Version 2.0, January 2004
 *                         http://www.apache.org/licenses/
 *
 *    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 *    1. Definitions.
 *
 *       "License" shall mean the terms and conditions for use, reproduction,
 *       and distribution as defined by Sections 1 through 9 of this document.
 *
 *       "Licensor" shall mean the copyright owner or entity authorized by
 *       the copyright owner that is granting the License.
 *
 *       "Legal Entity" shall mean the union of the acting entity and all
 *       other entities that control, are controlled by, or are under common
 *       control with that entity. For the purposes of this definition,
 *       "control" means (i) the power, direct or indirect, to cause the
 *       direction or management of such entity, whether by contract or
 *       otherwise, or (ii) ownership of fifty percent (50%) or more of the
 *       outstanding shares, or (iii) beneficial ownership of such entity.
 *
 *       "You" (or "Your") shall mean an individual or Legal Entity
 *       exercising permissions granted by this License.
 *
 *       "Source" form shall mean the preferred form for making modifications,
 *       including but not limited to software source code, documentation
 *       source, and configuration files.
 *
 *       "Object" form shall mean any form resulting from mechanical
 *       transformation or translation of a Source form, including but
 *       not limited to compiled object code, generated documentation,
 *       and conversions to other media types.
 *
 *       "Work" shall mean the work of authorship, whether in Source or
 *       Object form, made available under the License, as indicated by a
 *       copyright notice that is included in or attached to the work
 *       (an example is provided in the Appendix below).
 *
 *       "Derivative Works" shall mean any work, whether in Source or Object
 *       form, that is based on (or derived from) the Work and for which the
 *       editorial revisions, annotations, elaborations, or other modifications
 *       represent, as a whole, an original work of authorship. For the purposes
 *       of this License, Derivative Works shall not include works that remain
 *       separable from, or merely link (or bind by name) to the interfaces of,
 *       the Work and Derivative Works thereof.
 *
 *       "Contribution" shall mean any work of authorship, including
 *       the original version of the Work and any modifications or additions
 *       to that Work or Derivative Works thereof, that is intentionally
 *       submitted to Licensor for inclusion in the Work by the copyright owner
 *       or by an individual or Legal Entity authorized to submit on behalf of
 *       the copyright owner. For the purposes of this definition, "submitted"
 *       means any form of electronic, verbal, or written communication sent
 *       to the Licensor or its representatives, including but not limited to
 *       communication on electronic mailing lists, source code control systems,
 *       and issue tracking systems that are managed by, or on behalf of, the
 *       Licensor for the purpose of discussing and improving the Work, but
 *       excluding communication that is conspicuously marked or otherwise
 *       designated in writing by the copyright owner as "Not a Contribution."
 *
 *       "Contributor" shall mean Licensor and any individual or Legal Entity
 *       on behalf of whom a Contribution has been received by Licensor and
 *       subsequently incorporated within the Work.
 *
 *    2. Grant of Copyright License. Subject to the terms and conditions of
 *       this License, each Contributor hereby grants to You a perpetual,
 *       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *       copyright license to reproduce, prepare Derivative Works of,
 *       publicly display, publicly perform, sublicense, and distribute the
 *       Work and such Derivative Works in Source or Object form.
 *
 *    3. Grant of Patent License. Subject to the terms and conditions of
 *       this License, each Contributor hereby grants to You a perpetual,
 *       worldwide, non-exclusive, no-charge, royalty-free, irrevocable
 *       (except as stated in this section) patent license to make, have made,
 *       use, offer to sell, sell, import, and otherwise transfer the Work,
 *       where such license applies only to those patent claims licensable
 *       by such Contributor that are necessarily infringed by their
 *       Contribution(s) alone or by combination of their Contribution(s)
 *       with the Work to which such Contribution(s) was submitted. If You
 *       institute patent litigation against any entity (including a
 *       cross-claim or counterclaim in a lawsuit) alleging that the Work
 *       or a Contribution incorporated within the Work constitutes direct
 *       or contributory patent infringement, then any patent licenses
 *       granted to You under this License for that Work shall terminate
 *       as of the date such litigation is filed.
 *
 *    4. Redistribution. You may reproduce and distribute copies of the
 *       Work or Derivative Works thereof in any medium, with or without
 *       modifications, and in Source or Object form, provided that You
 *       meet the following conditions:
 *
 *       (a) You must give any other recipients of the Work or
 *           Derivative Works a copy of this License; and
 *
 *       (b) You must cause any modified files to carry prominent notices
 *           stating that You changed the files; and
 *
 *       (c) You must retain, in the Source form of any Derivative Works
 *           that You distribute, all copyright, patent, trademark, and
 *           attribution notices from the Source form of the Work,
 *           excluding those notices that do not pertain to any part of
 *           the Derivative Works; and
 *
 *       (d) If the Work includes a "NOTICE" text file as part of its
 *           distribution, then any Derivative Works that You distribute must
 *           include a readable copy of the attribution notices contained
 *           within such NOTICE file, excluding those notices that do not
 *           pertain to any part of the Derivative Works, in at least one
 *           of the following places: within a NOTICE text file distributed
 *           as part of the Derivative Works; within the Source form or
 *           documentation, if provided along with the Derivative Works; or,
 *           within a display generated by the Derivative Works, if and
 *           wherever such third-party notices normally appear. The contents
 *           of the NOTICE file are for informational purposes only and
 *           do not modify the License. You may add Your own attribution
 *           notices within Derivative Works that You distribute, alongside
 *           or as an addendum to the NOTICE text from the Work, provided
 *           that such additional attribution notices cannot be construed
 *           as modifying the License.
 *
 *       You may add Your own copyright statement to Your modifications and
 *       may provide additional or different license terms and conditions
 *       for use, reproduction, or distribution of Your modifications, or
 *       for any such Derivative Works as a whole, provided Your use,
 *       reproduction, and distribution of the Work otherwise complies with
 *       the conditions stated in this License.
 *
 *    5. Submission of Contributions. Unless You explicitly state otherwise,
 *       any Contribution intentionally submitted for inclusion in the Work
 *       by You to the Licensor shall be under the terms and conditions of
 *       this License, without any additional terms or conditions.
 *       Notwithstanding the above, nothing herein shall supersede or modify
 *       the terms of any separate license agreement you may have executed
 *       with Licensor regarding such Contributions.
 *
 *    6. Trademarks. This License does not grant permission to use the trade
 *       names, trademarks, service marks, or product names of the Licensor,
 *       except as required for reasonable and customary use in describing the
 *       origin of the Work and reproducing the content of the NOTICE file.
 *
 *    7. Disclaimer of Warranty. Unless required by applicable law or
 *       agreed to in writing, Licensor provides the Work (and each
 *       Contributor provides its Contributions) on an "AS IS" BASIS,
 *       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
 *       implied, including, without limitation, any warranties or conditions
 *       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
 *       PARTICULAR PURPOSE. You are solely responsible for determining the
 *       appropriateness of using or redistributing the Work and assume any
 *       risks associated with Your exercise of permissions under this License.
 *
 *    8. Limitation of Liability. In no event and under no legal theory,
 *       whether in tort (including negligence), contract, or otherwise,
 *       unless required by applicable law (such as deliberate and grossly
 *       negligent acts) or agreed to in writing, shall any Contributor be
 *       liable to You for damages, including any direct, indirect, special,
 *       incidental, or consequential damages of any character arising as a
 *       result of this License or out of the use or inability to use the
 *       Work (including but not limited to damages for loss of goodwill,
 *       work stoppage, computer failure or malfunction, or any and all
 *       other commercial damages or losses), even if such Contributor
 *       has been advised of the possibility of such damages.
 *
 *    9. Accepting Warranty or Additional Liability. While redistributing
 *       the Work or Derivative Works thereof, You may choose to offer,
 *       and charge a fee for, acceptance of support, warranty, indemnity,
 *       or other liability obligations and/or rights consistent with this
 *       License. However, in accepting such obligations, You may act only
 *       on Your own behalf and on Your sole responsibility, not on behalf
 *       of any other Contributor, and only if You agree to indemnify,
 *       defend, and hold each Contributor harmless for any liability
 *       incurred by, or claims asserted against, such Contributor by reason
 *       of your accepting any such warranty or additional liability.
 *
 *    END OF TERMS AND CONDITIONS
 *
 *    APPENDIX: How to apply the Apache License to your work.
 *
 *       To apply the Apache License to your work, attach the following
 *       boilerplate notice, with the fields enclosed by brackets "{}"
 *       replaced with your own identifying information. (Don't include
 *       the brackets!)  The text should be enclosed in the appropriate
 *       comment syntax for the file format. We also recommend that a
 *       file or class name and description of purpose be included on the
 *       same "printed page" as the copyright notice for easier
 *       identification within third-party archives.
 *
 *    Copyright {yyyy} {name of copyright owner}
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */
package com.deleidos.rtws.systemcfg.composer.impl;

import java.io.BufferedReader;
import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Writer;
import java.net.URL;
import java.util.ArrayList;
import java.util.Enumeration;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import javax.xml.bind.JAXBElement;
import javax.xml.bind.MarshalException;

import net.sf.json.JSONObject;

import org.apache.commons.codec.digest.DigestUtils;
import org.apache.commons.io.IOUtils;
import org.apache.commons.lang.StringUtils;
import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.codehaus.jackson.annotate.JsonAutoDetect.Visibility;
import org.codehaus.jackson.annotate.JsonMethod;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.annotate.JsonSerialize.Inclusion;
import org.codehaus.plexus.util.FileUtils;

import com.deleidos.rtws.appliance.playbook.SingleHostPlaybookGenerator;
import com.deleidos.rtws.commons.cloud.beans.ProcessDefinition;
import com.deleidos.rtws.commons.config.RtwsConfig;
import com.deleidos.rtws.commons.exception.DefaultConfigurationException;
import com.deleidos.rtws.commons.model.tmsdb.InstanceType;
import com.deleidos.rtws.commons.model.tmsdb.MachineImage;
import com.deleidos.rtws.commons.model.tmsdb.ProcessGroupConfig;
import com.deleidos.rtws.commons.net.jmx.JmxConnection;
import com.deleidos.rtws.master.core.AggregatingStatisticsCollector;
import com.deleidos.rtws.master.core.BoundsStatisticsCollector;
import com.deleidos.rtws.master.core.ConsensusScalingMonitor;
import com.deleidos.rtws.master.core.DiskUtilizationScalingMonitor;
import com.deleidos.rtws.master.core.ThroughputScalingMonitor;
import com.deleidos.rtws.master.core.beans.ClusterDefinition;
import com.deleidos.rtws.master.core.beans.ProcessAllocationPolicy;
import com.deleidos.rtws.master.core.beans.ProcessGroup;
import com.deleidos.rtws.master.core.beans.ScalingMonitor;
import com.deleidos.rtws.master.core.beans.StatisticsCollector;
import com.deleidos.rtws.master.core.net.jmx.JmxNodeFinder;
import com.deleidos.rtws.master.core.net.jmx.JmxStatisticsCollector;
import com.deleidos.rtws.master.core.net.jmx.RemoteJmxAggregatingStatisticsCollector;
import com.deleidos.rtws.master.core.util.JmsMemoryChoke;
import com.deleidos.rtws.systemcfg.bean.ComposerStatus;
import com.deleidos.rtws.systemcfg.bean.Container;
import com.deleidos.rtws.systemcfg.bean.DesiredState;
import com.deleidos.rtws.systemcfg.bean.Env;
import com.deleidos.rtws.systemcfg.bean.HostDir;
import com.deleidos.rtws.systemcfg.bean.Manifest;
import com.deleidos.rtws.systemcfg.bean.Pair;
import com.deleidos.rtws.systemcfg.bean.Pod;
import com.deleidos.rtws.systemcfg.bean.Port;
import com.deleidos.rtws.systemcfg.bean.Selector;
import com.deleidos.rtws.systemcfg.bean.Service;
import com.deleidos.rtws.systemcfg.bean.Source;
import com.deleidos.rtws.systemcfg.bean.SystemContext;
import com.deleidos.rtws.systemcfg.bean.Transport;
import com.deleidos.rtws.systemcfg.bean.Volume;
import com.deleidos.rtws.systemcfg.bean.VolumeMount;
import com.deleidos.rtws.systemcfg.bean.Webapp;
import com.deleidos.rtws.systemcfg.composer.DefinitionComposer;
import com.deleidos.rtws.systemcfg.exception.ComposerException;
import com.deleidos.rtws.systemcfg.serialize.DefinitionSerializer;
import com.deleidos.rtws.systemcfg.userinput.bean.SystemConfig;
import com.deleidos.rtws.systemcfg.userinput.bean.UserProcessGroupConfig;
import com.deleidos.rtws.systemcfg.util.RtwsProperties;
import com.deleidos.rtws.systemcfg.util.SystemBuilderUtil;


public class ClusterDefinitionComposer implements DefinitionComposer {
	
	private static Logger logger = LogManager.getLogger(ClusterDefinitionComposer.class);
	private ClusterDefinition clusterDefinition;
	private DefinitionSerializer serializer;
	private ObjectMapper mapper = new ObjectMapper();
	private String outputDir;
	private RtwsProperties properties;
	//used for scaling collectors
	private String internalCollector = "messaging.internal.node?.jmx.url";
	private String externalCollector = "messaging.external.node?.jmx.url";
	private final String externalQueue = "messaging.queue.parse.name";
	private String defaultOutputFilename = "services.xml";
	private final String ansibleTemplateResourceDirectory = "/templates/centos7-standalone.tar";
	private final String ansibleDirectoryName = "/ansible";
	private final String confDir = "/master/";
	private String baseDir;
	private final String filter = "filter";
	private String tenantId;
	
	/**
	 * Initialize composer.
	 */
	@Override
	public void initialize() {
		serializer.initialize();
		mapper.setVisibility(JsonMethod.FIELD, Visibility.ANY);
		mapper.setSerializationInclusion(Inclusion.NON_DEFAULT);
		
		String templateFile = null;
		baseDir = (String) RtwsConfig.getInstance().getConfiguration().getProperty("sysbuilder.template.basedir");
		
		//initialize template file locations
		//template file property sets, for lookup in composer later
		templateFile = String.format("%s/%s", baseDir, "services-template.xml");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.service.template", templateFile);
		
		templateFile = String.format("%s/%s", baseDir, "ingest-all-choke-template.xml");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.ingest.all.choke.template", templateFile);
		
		templateFile = String.format("%s/%s", baseDir, "ingest-all-scaling-template.xml");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.ingest.all.scaling.template", templateFile);
		
		templateFile = String.format("%s/%s", baseDir, "default.properties");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.service.default.properties", templateFile);
		
		templateFile = String.format("%s/%s", baseDir, "activemq-template.xml");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.activemq.template", templateFile);
		
		templateFile = String.format("%s/%s", baseDir, "docker.run.header.txt");
		RtwsConfig.getInstance().getConfiguration().setProperty("sysbuilder.docker.run.header.template", templateFile);
	}
	
	/**
	 * Writes composer generated objects to a file.
	 */
	@Override
	public void writeFile(String version, String fileName) {
		try {
			if(fileName == null){
				serializer.createDefinitionFile(clusterDefinition, new File(outputDir + defaultOutputFilename));
			}
			else{
				serializer.createDefinitionFile(clusterDefinition, new File(outputDir + fileName));
			}
		} catch(Exception e) {
			e.printStackTrace();
			logger.error(e.toString(), e);
		}
	}
	
	/**
	 * Loads default configuration files, this includes templates.
	 */
	@Override
	public void loadDefaults(String version, SystemConfig config, SystemContext systemContext, RtwsProperties properties) throws MarshalException, DefaultConfigurationException {
		try{
			this.properties = properties;  //initialize properties
			this.outputDir = config.getOutputConfDir() + this.confDir;  //set outupt directory for files.
			SystemBuilderUtil.mkdir(this.outputDir);  //create directory
			String file = RtwsConfig.getInstance().getString("sysbuilder.service.template");  //get file from properties
			
			//replace markers before file is unmarshalled to object
			String templateString = replaceMarkers(file, systemContext);

			//pass template to a stream to be unmarshalled
			InputStream is = new ByteArrayInputStream(templateString.toString().getBytes());
			
			//unmarshall cluster template to object
			clusterDefinition = serializer.createObject(is, ClusterDefinition.class);
			clusterDefinition.setDomainName("master." + config.getSystemDomain());
			
			if (config.getVpcEnabled()) {
				clusterDefinition.setPrivateSubnetId(config.getSubnetId());
			}
		}
		catch(Exception e){
			logger.error(e.toString(), e);
			e.printStackTrace();
			throw new DefaultConfigurationException(e.toString(), e);
		}
	}
	
	/**
	 * Generate files/configuration for cluster.
	 * @throws ComposerException 
	 */
	@Override
	public ComposerStatus compose(SystemConfig config, SystemContext systemContext) throws ComposerException {
		ComposerStatus status = ComposerStatus.done;
		
		try{			
			createProcessGroup(config, systemContext);
			if (config.getApplianceEnabled()) {
				validateInstanceTypes(config,systemContext);
				createProcessGroupContainerRunStatements(config, systemContext);
				createProcessGroupContainerFilesystemGenerationStatements(config, systemContext);
				createKubernetesDefinitions(config, systemContext);
				try {
					generateSingleHostPlaybook(config);
				} catch (IOException e) {
					logger.error("Playbook not successfully generated.");
					logger.error(e.getMessage());
				}
			}
		}
		catch(ComposerException ce){
			status = ComposerStatus.error;
			throw ce;  //rethrow
		}
		catch(Exception e){
			logger.error(e.toString(),e );
			status = ComposerStatus.error;
			throw new ComposerException(e.toString(), e);
		}
		
		return status;
	}

	private void generateSingleHostPlaybook(SystemConfig config) throws IOException  {
		SingleHostPlaybookGenerator singleHostPlaybookGenerator = new SingleHostPlaybookGenerator();
		InputStream resourceTarStream = getClass().getResourceAsStream(ansibleTemplateResourceDirectory);
		singleHostPlaybookGenerator.setBaseOutputDir(new File(outputDir+File.separator+ansibleDirectoryName), true);
		singleHostPlaybookGenerator.extractInputStreamToBaseOutputDir(resourceTarStream);
		singleHostPlaybookGenerator.getGeneratedOutputFile().getName();
		
		singleHostPlaybookGenerator.init(config.getApplianceDomain(), config.getSoftwareVersion());
		logger.info("Running file generators.");
		singleHostPlaybookGenerator.runGenerators();
		singleHostPlaybookGenerator.compressGeneratedAnsibleDirectoryToOutput();
		if(singleHostPlaybookGenerator.getGeneratedOutputFile().exists()) {
			logger.info(this.getClass() + ": output file detected in " 
					+ singleHostPlaybookGenerator.getGeneratedOutputFile().getAbsolutePath());
		}
		moveGeneratedPlaybookToModifiedFilesDirectory(singleHostPlaybookGenerator.getGeneratedOutputFile(), config.getApplianceDomain());
	}
	
	private boolean moveGeneratedPlaybookToModifiedFilesDirectory(File generatedFile, String applianceDomain) {
		StringBuilder tmpManifestDir = new StringBuilder();
		tmpManifestDir.append("/tmp/templateManifest/").append(applianceDomain).append("/out/");
		File manifestDir = new File(tmpManifestDir.toString());
		return moveGeneratedPlaybook(generatedFile, manifestDir);
	}
	
	private boolean moveGeneratedPlaybook(File generatedTarFile, File destinationDirectory) {
		try {
			FileUtils.copyFileToDirectory(generatedTarFile, destinationDirectory);
			return true;
		} catch (IOException e) {
			logger.error("Failed to move " + generatedTarFile + " to " + destinationDirectory + ".");
			logger.error(e.getMessage());
			return false;
		}
	}

	private void validateInstanceTypes(SystemConfig config, SystemContext systemContext) throws ComposerException {
		for (ProcessGroup processGroup : clusterDefinition.getProcessGroups()) {
			boolean found = false;
			for (InstanceType instanceType : systemContext.getInstanceTypes()) {
				if (instanceType.getInstanceType().equals(processGroup.getDefinition().getType())) {
					found = true;
				}
			}
			
			
			if (!found)
				throw new ComposerException(String.format("Sorry, instance type {%s} is not supported.  Please contact your DigitalEdge support representative to address this issue.", processGroup.getDefinition().getType()));
		}		
	}

	private void createKubernetesDefinitions(SystemConfig config, SystemContext systemContext) throws IOException {

		List<String> kubernetesCreateStmts = new ArrayList<String>(clusterDefinition.getProcessGroups().size());
		kubernetesCreateStmts.add("export KUBERNETES_PROVIDER=local");
		kubernetesCreateStmts.add(System.getProperty("line.separator"));

		// Spit each process group out as it's own pod
		for (ProcessGroup processGroup : clusterDefinition.getProcessGroups()) {

			for (ProcessGroupConfig pgrpCfg : systemContext.getProcessGroupConfigs()) {

				if (pgrpCfg.getProcessGroupName().equals(processGroup.getName())) {

					this.properties.setProperty("build.domain.prefix", config.getApplianceDomain().split("\\.")[0].replace('?', ' '));	

					Service service = null;
					String validId = processGroup.getName().replaceAll("\\.", "-");

					// Pod		
					Pod pod = new Pod();
					pod.setId(validId);
					pod.setApiVersion("v1beta1");
					pod.setKind("Pod");
					pod.withLabel("digitaledge-domain",config.getApplianceDomain());
					pod.withLabel("digitaledge-fqdn",processGroup.getAllocationPolicy().getFqdn().replace('?', '1'));


					if (pgrpCfg.isServiceEnabled()) {
						// Service
						service = new Service();
						service.setId(validId);
						service.setApiVersion("v1beta1");
						service.setKind("Service");
						service.withSelector(new Selector().withName(validId));
					}


					Container container = new Container();
					container.setName(this.properties.get("docker.container.name"));
					
					// TODO when appropriate, make this externally configurable
					this.properties.remove("docker.image.reusable.prefix");
					if (processGroup.getName().equals("kibana")) {
						this.properties.setProperty("docker.image.reusable.prefix", "kibana");
						container.setImage(this.properties.get("docker.container.image.reusable.name"));

					} else if (processGroup.getName().equals("mongodb.standalone")) {
						this.properties.setProperty("docker.image.reusable.prefix", "mongod");
						container.setImage(this.properties.get("docker.container.image.reusable.name"));

					} else {
						container.setImage(this.properties.get("docker.container.image.name"));
					}
					
					

					String processGroupType = processGroup.getDefinition().getType();
					for (InstanceType instanceType : systemContext.getInstanceTypes()) {
						if (instanceType.getInstanceType().equals(processGroupType)) {
							container.setMemory(Long.valueOf(instanceType.getMemoryMB()) * 1048576l);	
							this.properties.setProperty("memory.limit", String.valueOf(instanceType.getMemoryMB()) + "m");
							this.properties.setProperty("memory.limit.without.unit", String.valueOf(instanceType.getMemoryMB()));
							break;
						}
					}	


					if (pgrpCfg.getProcessGroupName().equals(processGroup.getName())) {
						if (pgrpCfg.getContainerPortExpose() != null) {
							String[] ports = pgrpCfg.getContainerPortExpose().split(",");
							for (String port : ports) {
								if (port.contains("-")) {
									logger.info("port: " + port);
									String [] range = port.split("-");
									for(int i = Integer.valueOf(range[0]); i < Integer.valueOf(range[1]);i++)
										container.withPort(new Port().withContainerPort(i));

									// Just grab the 1st one on ranges
									if (pgrpCfg.isServiceEnabled())
										service.withPort(Integer.valueOf(range[0]));
								} else {
									container.withPort(new Port().withContainerPort(Integer.valueOf(port)));
									if (pgrpCfg.isServiceEnabled())
										service.withPort(Integer.valueOf(port));
								}
							}
						}

						if (pgrpCfg.getContainerPortExposeHost() != null) {
							String[] ports = pgrpCfg.getContainerPortExposeHost().split(",");
							for (String port : ports) {
								if (port.contains(":")) {
									// expected to be in the form hostport:containerport
									container
									.withPort(new Port()
									.withContainerPort(Integer.valueOf( port.split(":")[1]))
									.withHostPort(Integer.valueOf(port.split(":")[0]))); 
								} else {
									container
									.withPort(new Port()
									.withContainerPort(Integer.valueOf(port))
									.withHostPort(Integer.valueOf(port))); 
								}

								if (pgrpCfg.isServiceEnabled())
									service.withPort(Integer.valueOf(port));
							}
						}
					}


					if (processGroup.getName().equals("transport")) {				
						List<Transport> transports = config.getTransports();				
						for (Transport transport : transports) {
							if (logger.isDebugEnabled())
								logger.debug(String.format("Transport: %s", transport.getFqn()));

							for (Pair param : transport.getParams()) {
								if (logger.isDebugEnabled())
									logger.debug(String.format("Transport: %s param: {%s  => %s}", transport.getFqn(),param.getName(),param.getValue()));

								/* TODO replace with a more sophisticated method of determining which 
								 * transport parameter corresponds to the listening port
								 * 
								 */
								if (param.getName().equals("listen-port")) {
									container
									.withPort(new Port()/*
									.withProtocol(Port.Protocol.UDP)
									.withProtocol(Port.Protocol.TCP)*/									
									.withContainerPort(Integer.valueOf(param.getValue()))
									.withHostPort(Integer.valueOf(param.getValue())));							
								}
							}
						}				
					}

					// Add environment variables
					this.properties.setProperty("process.group.prefix", 
							processGroup.getAllocationPolicy().getFqdn().split("\\.")[0].replace('?', '1'));
					this.properties.setProperty("process.group", processGroup.getName());
					this.properties.setProperty("build.domain.prefix", config.getApplianceDomain().split("\\.")[0].replace('?', '1'));
					this.properties.setProperty("rtws.bypass", "");

					Properties props = new Properties();
					if (logger.isDebugEnabled())
						logger.debug("docker.container.env=" + this.properties.get("docker.container.env"));
					String [] tokens = this.properties.get("docker.container.env").split(";");
					for (String token : tokens) {
						if (logger.isDebugEnabled())
							logger.debug("token:" + token);
						String[] parts = token.split("=");
						if (parts.length >= 2) {
							props.put(parts[0].trim(), parts[1].trim());
						} else {
							// case for passing in RTWS_BYPASS= & RTWS_INGEST_CONFIG=
							props.put(parts[0].trim(), "");
						}
					}

					Enumeration<Object> keys = props.keys();
					while (keys.hasMoreElements()) {
						String key = (String) keys.nextElement();
						Env env = new Env();
						env.setName(key);
						env.setValue(props.getProperty(key));
						container.withEnv(env);
					}

					Manifest manifest = new Manifest().withContainer(container);
					manifest.setId(validId);
					manifest.setVersion("v1beta1");

					// Configure Volume Mounts
					JSONObject def = JSONObject.fromObject(pgrpCfg.getConfigPermissions());
					if (logger.isDebugEnabled()) {
						logger.debug(config.getApplianceDomain());
						logger.debug(processGroup.getAllocationPolicy().getFqdn());
					}
					if (def.getInt("default-num-volumes") > 0 ) {
						// Map<HOST_PATH,CONTAINER_PATH>
						Map<String,String> volumeCfg = new HashMap<String,String>();
						volumeCfg.put("/etc/de/certs","/tmp/certs");
						volumeCfg.put(
								String.format("/%s/%s",
										DigestUtils.sha256Hex(config.getApplianceDomain()),
										DigestUtils.sha256Hex(
												processGroup.getAllocationPolicy().getFqdn().split("\\.")[0].replace('?', '1'))),
								"/mnt/rdafs");

						Iterator<String> hostPathIterator = volumeCfg.keySet().iterator();
						int i = 1;
						while (hostPathIterator.hasNext()) {
							String key = hostPathIterator.next();
							String val = volumeCfg.get(key);

							Volume vol = new Volume();
							vol.setName(String.format("vol%s",i));
							Source certsSource = new Source();
							HostDir dir = new HostDir()
							.withPath(key);
							certsSource.withHostDir(dir);
							vol.setSource(certsSource);
							manifest.withVolume(vol);
							VolumeMount volumeMount = new VolumeMount().withMountPath(val);
							volumeMount.setName(String.format("vol%s",i));
							container.withVolumeMount(volumeMount);

							i++;
						}

					} else {
						this.properties.setProperty("volume.mapping","-v /etc/de/certs:/tmp/certs");
						Volume vol = new Volume();
						vol.setName("certs");
						Source certsSource = new Source();
						HostDir dir = new HostDir().withPath("/etc/de/cert");
						certsSource.withHostDir(dir);
						vol.setSource(certsSource);
						manifest.withVolume(vol);
						VolumeMount volumeMount = new VolumeMount().withMountPath("/tmp/certs");
						volumeMount.setName("certs");
						container.withVolumeMount(volumeMount);
					}

					DesiredState desiredState = new DesiredState(manifest);


					// Pod
					pod.setDesiredState(desiredState);
					Writer writer = new FileWriter(outputDir + processGroup.getName() + "_pod.json");
					IOUtils.write(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(pod), writer);
					IOUtils.closeQuietly(writer);

					this.properties.setProperty("kubernetes.component.json", "/tmp/" + processGroup.getName() + "_pod.json");
					kubernetesCreateStmts.add(this.properties.get("kubernetes.create.template"));
					kubernetesCreateStmts.add(System.getProperty("line.separator"));	
					kubernetesCreateStmts.add("sleep 30");	
					kubernetesCreateStmts.add(System.getProperty("line.separator"));	
					this.properties.setProperty("kubernetes.component.json", "");



					if (pgrpCfg.isServiceEnabled()) {
						// Service
						writer = new FileWriter(outputDir + processGroup.getName() + "_service.json");
						IOUtils.write(mapper.writerWithDefaultPrettyPrinter().writeValueAsString(service), writer);
						IOUtils.closeQuietly(writer);

						this.properties.setProperty("kubernetes.component.json", "/tmp/" + processGroup.getName() + "_service.json");
						kubernetesCreateStmts.add(this.properties.get("kubernetes.create.template"));
						kubernetesCreateStmts.add(System.getProperty("line.separator"));	
						kubernetesCreateStmts.add("sleep 30");	
						kubernetesCreateStmts.add(System.getProperty("line.separator"));	
						this.properties.setProperty("kubernetes.component.json", "");
					}
				}
			}
		}

		Writer writer = new FileWriter(outputDir + "kubectl.run");
		IOUtils.writeLines(kubernetesCreateStmts, System.getProperty("line.separator"), writer);
		IOUtils.closeQuietly(writer);
	}

	private void createProcessGroupContainerFilesystemGenerationStatements(SystemConfig config,
			SystemContext systemContext) throws IOException {
		// Generate template ZFS filesystem creation statements
		List<String> stmts = new ArrayList<String>(clusterDefinition.getProcessGroups().size());


		// always include the gateway
		for (ProcessGroupConfig pgrpCfg : systemContext.getProcessGroupConfigs()) {
			if (pgrpCfg.getProcessGroupName().equals("gateway")) {					

				JSONObject def = JSONObject.fromObject(pgrpCfg.getConfigPermissions());
				int i = 1;
				if (def.getInt("default-num-volumes") > 0 ) {				
					this.properties.setProperty("process.group.prefix", "gateway");
					this.properties.setProperty("process.group", pgrpCfg.getProcessGroupName());
					this.properties.setProperty("build.domain.prefix", config.getApplianceDomain().split("\\.")[0].replace('?', (char) (i + 48)));
					
					this.properties.setProperty("filesystem.quota", Integer.toString(def.getInt("default-num-volumes") * def.getInt("default-num-volumes")));	
					this.properties.setProperty("fqdn",	DigestUtils.sha256Hex("gateway"));
					this.properties.setProperty("mount.point", 
							String.format("/%s/%s" ,
									DigestUtils.sha256Hex(config.getApplianceDomain()),
									DigestUtils.sha256Hex(pgrpCfg.getPublicDomainName().split("\\.")[0].replace('?', (char) (i + 48)))));

					stmts.add(this.properties.get("zfs.filesystem.creation.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.domain.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.processgroup.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.compression.template"));
					stmts.add(System.getProperty("line.separator"));

				}
			}
		}

		for (ProcessGroup processGroup : clusterDefinition.getProcessGroups()) {
			ProcessDefinition def = processGroup.getDefinition();
			if (def.getVolumeCount() > 0 ) {				
				for (int i = 1; i <= processGroup.getAllocationPolicy().getMax();i++) {
					this.properties.setProperty("process.group.prefix", 
							processGroup.getAllocationPolicy().getFqdn().split("\\.")[0].replace('?', (char) (i + 48)));
					this.properties.setProperty("filesystem.quota", Integer.toString(def.getVolumeSize() * def.getVolumeCount()));	
					this.properties.setProperty("fqdn", 
							DigestUtils.sha256Hex(processGroup.getAllocationPolicy().getFqdn().replace('?', (char) (i + 48))));
					this.properties.setProperty("mount.point", 
							String.format("/%s/%s" ,
									DigestUtils.sha256Hex(config.getApplianceDomain()),
									DigestUtils.sha256Hex(processGroup.getAllocationPolicy()
											.getFqdn().split("\\.")[0].replace('?', (char) (i + 48)))));

					stmts.add(this.properties.get("zfs.filesystem.creation.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.domain.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.processgroup.template"));
					stmts.add(System.getProperty("line.separator"));

					stmts.add(this.properties.get("zfs.filesystem.property.compression.template"));
					stmts.add(System.getProperty("line.separator"));
				}
			}
		}

		Writer writer = new FileWriter(outputDir + "zfs.create");
		IOUtils.writeLines(stmts, System.getProperty("line.separator"), writer);
		IOUtils.closeQuietly(writer);

	}

	private void createProcessGroupContainerRunStatements(SystemConfig config, SystemContext systemContext) 
			throws MarshalException, DefaultConfigurationException, IOException {
		// Generate template Docker run statements
		List<String> dockerRunStmts = new ArrayList<String>(clusterDefinition.getProcessGroups().size());
		
		String header = "";
		StringBuilder templateString = new StringBuilder();
		BufferedReader bin = null;
		try {
			bin = new BufferedReader(new InputStreamReader(getClass().getResourceAsStream(RtwsConfig.getInstance().getString("sysbuilder.docker.run.header.template"))));
			String line = null;
			while ((line = bin.readLine()) != null){
				templateString.append(line);
				templateString.append("\n");
			}//end while
			
		} finally {
			IOUtils.closeQuietly(bin);
		}
		header = templateString.toString();
		
		this.properties.setProperty("port.mapping","");
		this.properties.setProperty("ingest.config.filename","");
		// always include the gateway
		for (ProcessGroupConfig pgrpCfg : systemContext.getProcessGroupConfigs()) {
			if (pgrpCfg.getProcessGroupName().equals("gateway")) {
				StringBuilder hostToContainerPortMappings = new StringBuilder(8);
				StringBuilder exposePortMappings = new StringBuilder(8);

				if (pgrpCfg.getContainerPortExpose() != null) {
					String[] ports = pgrpCfg.getContainerPortExpose().split(",");
					for (String port : ports) {
						exposePortMappings.append(String.format("--expose %s ", port));
					}
				}

				if (pgrpCfg.getContainerPortExposeHost() != null) {
					String[] portMaps = pgrpCfg.getContainerPortExposeHost().split(",");
					// portMap is expected to be in the form hostport:containerport
					for (String portMap : portMaps) {
						hostToContainerPortMappings.append(String.format("-p %s ", portMap));
					}
				}


				for (int i = 1; i <= 1;i++) {
					this.properties.setProperty("process.group.prefix", "gateway");
					this.properties.setProperty("process.group", pgrpCfg.getProcessGroupName());
					this.properties.setProperty("build.domain.prefix", config.getApplianceDomain().split("\\.")[0].replace('?', (char) (i + 48)));
					JSONObject def = JSONObject.fromObject(pgrpCfg.getConfigPermissions());

					if (def.getInt("default-num-volumes") > 0 ) {
						// Convention is to mount the volume(s) on the host under 
						// /sha256(applianceDomain)/sha256(process.group.fqdn.prefix)
						// e.g)
						// -v /test-logs.logs.elastic4.com/jms-ext-node1:/mnt/rdafs \
						this.properties.setProperty("volume.mapping", 
								String.format("-v /etc/de/certs:/tmp/certs -v /%s/%s:/mnt/rdafs",
										DigestUtils.sha256Hex(config.getApplianceDomain()),
										DigestUtils.sha256Hex(pgrpCfg.getPublicDomainName().split("\\.")[0].replace('?', (char) (i + 48)))));
					} else {
						this.properties.setProperty("volume.mapping","-v /etc/de/certs:/tmp/certs");
					}

					String processGroupType = pgrpCfg.getDefaultInstanceType();
					for (InstanceType instanceType : systemContext.getInstanceTypes()) {
						if (instanceType.getInstanceType().equals(processGroupType)) {
							this.properties.setProperty("memory.limit", String.valueOf(instanceType.getMemoryMB()) + "m");
							this.properties.setProperty("memory.limit.without.unit", String.valueOf(instanceType.getMemoryMB()));
							break;
						}
					}

					dockerRunStmts.add(this.properties.get("docker.run.template"));
					dockerRunStmts.add(System.getProperty("line.separator"));	
					dockerRunStmts.add("sleep 30");	
					dockerRunStmts.add(System.getProperty("line.separator"));	
				}

			}
		}

		
		
		
		
		
		// Generate remaining, non-gateway, process group statements
		for (ProcessGroup processGroup : clusterDefinition.getProcessGroups()) {
			ProcessDefinition def = processGroup.getDefinition();			
			StringBuilder hostToContainerPortMappings = new StringBuilder(8);
			StringBuilder exposePortMappings = new StringBuilder(8);
			this.properties.setProperty("port.mapping","");
			this.properties.setProperty("ingest.config.filename","");

			for (ProcessGroupConfig pgrpCfg : systemContext.getProcessGroupConfigs()) {


				if (pgrpCfg.getProcessGroupName().equals(processGroup.getName())) {
					if (pgrpCfg.getContainerPortExpose() != null) {
						String[] ports = pgrpCfg.getContainerPortExpose().split(",");
						for (String port : ports) {
							exposePortMappings.append(String.format("--expose %s ", port));
						}
					}

					if (pgrpCfg.getContainerPortExposeHost() != null) {
						String[] ports = pgrpCfg.getContainerPortExposeHost().split(",");
						for (String port : ports) {
							// portMap is expected to be in the form hostport:containerport
							hostToContainerPortMappings.append(String.format("-p %s ", port));
						}
					}

					this.properties.setProperty("port.mapping",String.format("%s %s",
							hostToContainerPortMappings.toString(), exposePortMappings.toString()));
					
					
					String processGroupType = def.getType();
					for (InstanceType instanceType : systemContext.getInstanceTypes()) {
						if (instanceType.getInstanceType().equals(processGroupType)) {
							this.properties.setProperty("memory.limit", String.valueOf(instanceType.getMemoryMB()) + "m");
							this.properties.setProperty("memory.limit.without.unit", String.valueOf(instanceType.getMemoryMB()));
							break;
						}
					}
					
					// Provide information for RTWS_INGEST_CONFIG
					if (processGroup.getName().contains("datasink") || processGroup.getName().contains("ingest.all")) {
						if(StringUtils.isNotEmpty(pgrpCfg.getIngestConfigFilename()) == true){
							properties.put("ingest.config.filename", pgrpCfg.getIngestConfigFilename());
						}
					}
				}
			}


			if (processGroup.getName().equals("transport")) {				
				List<Transport> transports = config.getTransports();				
				for (Transport transport : transports) {
					if (logger.isDebugEnabled())
						logger.debug(String.format("Transport: %s", transport.getFqn()));

					for (Pair param : transport.getParams()) {
						if (logger.isDebugEnabled())
							logger.debug(String.format("Transport: %s param: {%s  => %s}", transport.getFqn(),param.getName(),param.getValue()));

						/* TODO replace with a more sophisticated method of determining which 
						 * transport parameter corresponds to the listening port
						 * 
						 */
						if (param.getName().equals("listen-port")) {
							hostToContainerPortMappings.append(String.format("-p %s:%s/udp -p %s:%s/tcp ",param.getValue(),param.getValue(),param.getValue(),param.getValue()));
						}
					}
				}				
			}

			this.properties.setProperty("port.mapping",String.format("%s %s",
					hostToContainerPortMappings.toString(), exposePortMappings.toString()));


			String processGroupType = def.getType();
			for (InstanceType instanceType : systemContext.getInstanceTypes()) {
				if (instanceType.getInstanceType().equals(processGroupType)) {
					this.properties.setProperty("memory.limit", String.valueOf(instanceType.getMemoryMB()) + "m");
					this.properties.setProperty("memory.limit.without.unit", String.valueOf(instanceType.getMemoryMB()));
					break;
				}
			}

			for (int i = 1; i <= processGroup.getAllocationPolicy().getMax();i++) {
				this.properties.setProperty("process.group.prefix", 
						processGroup.getAllocationPolicy().getFqdn().split("\\.")[0].replace('?', (char) (i + 48)));
				this.properties.setProperty("process.group", processGroup.getName());
				this.properties.setProperty("build.domain.prefix", config.getApplianceDomain().split("\\.")[0].replace('?', (char) (i + 48)));			
				if (def.getVolumeCount() > 0 ) {
					// Convention is to mount the volume(s) on the host under 
					// /sha256(applianceDomain)/sha256(process.group.fqdn.prefix)
					// e.g)
					// -v /test-logs.logs.elastic4.com/jms-ext-node1:/mnt/rdafs \
					this.properties.setProperty("volume.mapping", 
							String.format("-v /etc/de/certs:/tmp/certs -v /%s/%s:/mnt/rdafs",
									DigestUtils.sha256Hex(config.getApplianceDomain()),
									DigestUtils.sha256Hex(processGroup.getAllocationPolicy()
											.getFqdn().split("\\.")[0].replace('?', (char) (i + 48)))));
				} else {
					this.properties.setProperty("volume.mapping","-v /etc/de/certs:/tmp/certs");
				}
				
				
				// TODO when appropriate, make this externally configurable
				this.properties.remove("docker.image.reusable.prefix");
				if (processGroup.getName().equals("kibana")) {
					this.properties.setProperty("docker.image.reusable.prefix", "kibana");
					dockerRunStmts.add(this.properties.get("docker.run.reusable.template"));

				} else if (processGroup.getName().equals("mongodb.standalone")) {
					this.properties.setProperty("docker.image.reusable.prefix", "mongod");
					dockerRunStmts.add(this.properties.get("docker.run.reusable.template"));

				} else {
					dockerRunStmts.add(this.properties.get("docker.run.template"));
				}
				
				dockerRunStmts.add(System.getProperty("line.separator"));	
				dockerRunStmts.add("sleep 30");	
				dockerRunStmts.add(System.getProperty("line.separator"));	
			}
		}

		Writer writer = new FileWriter(outputDir + "docker.run");
		writer.write(header);
		IOUtils.writeLines(dockerRunStmts, System.getProperty("line.separator"), writer);
		writer.write(System.getProperty("line.separator"));
		writer.write(System.getProperty("line.separator"));

		// Print out how much CPU/Memory this appliance will require and which AWS instance is best suited for it.
		List<String> cUsage = calculateApplianceUsage(config, systemContext);
		for (String usg : cUsage) {
			logger.info(usg);
		}		
		
		IOUtils.writeLines(cUsage, System.getProperty("line.separator"), writer);
		writer.write(System.getProperty("line.separator"));
		writer.write(System.getProperty("line.separator"));	

		IOUtils.closeQuietly(writer);
	}

	private List<String> calculateApplianceUsage(SystemConfig config, SystemContext systemContext) {
		int applianceMemoryRequirements = 0;
		int applianceCoreRequirements = 0;
		int applianceDiskRequirements = 0;		
		boolean foundSuitableInstanceType = false;
		List<String> usage = new ArrayList<String>();

		for (ProcessGroupConfig pgrpCfg : systemContext.getProcessGroupConfigs()) {
			if (pgrpCfg.getProcessGroupName().equals("gateway")) {
				for (InstanceType instanceType : systemContext.getInstanceTypes()) {
					if (instanceType.getInstanceType().equals(pgrpCfg.getDefaultInstanceType())) {
						logger.info(String.format("found for {%s}. instanceType: {%s} numCores: {%d} memoryMb: {%d}",
								pgrpCfg.getPublicDomainName(),
								pgrpCfg.getDefaultInstanceType(),
								instanceType.getNumCores(),
								instanceType.getMemoryMB()));
						applianceCoreRequirements += instanceType.getNumCores();
						applianceMemoryRequirements += instanceType.getMemoryMB();
					}
				}

				JSONObject def = JSONObject.fromObject(pgrpCfg.getConfigPermissions());

				if (def.getInt("default-num-volumes") > 0 ) {
					for(int v=1; v < def.getInt("default-num-volumes");v++) {
						applianceDiskRequirements += def.getInt("default-volume-size"); 
					}
				}
			}
		}


		for (ProcessGroup processGroup : clusterDefinition.getProcessGroups()) {

			for (int i = processGroup.getAllocationPolicy().getMin(); i <= processGroup.getAllocationPolicy().getMax();i++)
				applianceDiskRequirements += processGroup.getDefinition().getVolumeSize() * processGroup.getDefinition().getVolumeCount();			

			for (InstanceType instanceType : systemContext.getInstanceTypes()) {
				if (instanceType.getInstanceType().equals(processGroup.getDefinition().getType())) {
					logger.info(String.format("found for {%s}. instanceType: {%s} numCores: {%d} memoryMb: {%d}",
							processGroup.getName(),
							processGroup.getDefinition().getType(),
							instanceType.getNumCores(),
							instanceType.getMemoryMB()));
					applianceCoreRequirements += instanceType.getNumCores();
					applianceMemoryRequirements += instanceType.getMemoryMB();
				}
			}
		}

			
		for (InstanceType instanceType : systemContext.getInstanceTypes()) {
			if (instanceType.getNumCores() >= applianceCoreRequirements
					&& instanceType.getMemoryMB() >= applianceMemoryRequirements) {
				usage.add(String.format("# %s will require {%s} cores, {%s}(MB) of memory and {%s}(GB) of disk space for application storage which {%s} is a suitable instance type."
						,config.getApplianceDomain()
						,applianceCoreRequirements
						,applianceMemoryRequirements
						,applianceDiskRequirements
						,instanceType.getInstanceType()));		
				foundSuitableInstanceType = true;
			}
		}

		if (!foundSuitableInstanceType) {
			
			usage.add(String.format("# %s will require {%s} cores, {%s}(MB) of memory and {%s}(GB) of disk space for application storage."
					,config.getApplianceDomain()
					,applianceCoreRequirements
					,applianceMemoryRequirements
					,applianceDiskRequirements));
		}		

		return usage;
	}

	/**
	 * Dispose of serializer.
	 */
	@Override
	public void dispose() {
		serializer.dispose();
	}
	
	/**
	 * Get properties from composer.
	 */
	@Override
	public Properties getProperties() {
		return properties;
	}

	/**
	 * Set {@link DefinitionSerializer} for the composer.
	 * 
	 * @param serializer
	 */
	public void setDefinitionSerializer(DefinitionSerializer serializer){
		this.serializer = serializer;
	}
	
	/**
	 * Replace template markers in the cluster file template.
	 * 
	 * @param file
	 * @param systemContext
	 * @return
	 * @throws ComposerException 
	 */
	private String replaceMarkers(String file, SystemContext systemContext) throws ComposerException{

		StringBuilder templateString = new StringBuilder();
		BufferedReader bin;
		try {
			bin = new BufferedReader(new InputStreamReader(getClass().getResourceAsStream(file)));
			String line = null;
			while ((line = bin.readLine()) != null){
				templateString.append(line);
			}//end while
			bin.close();
		} catch (Exception e) {
			logger.error(e.toString(), e);
			e.printStackTrace();
			throw new ComposerException(e.toString(), e);
		}
				
		return templateString.toString();
	}	
	
	/**
	 * Create process groups based on user input.
	 * @param config
	 * @param systemContext
	 * @throws ComposerException
	 */
	private void createProcessGroup(SystemConfig config, SystemContext systemContext) throws ComposerException{
		//set tagging option, defaults to true
		if(!"AWS".equals(config.getServiceProvider())){
			clusterDefinition.setTaggingEnabled(false);
		}
		
		for(UserProcessGroupConfig userConfig : config.getProcessGroups()){
			ProcessGroupConfig processConfig = SystemBuilderUtil.getProcessGroup(userConfig.getProcessGroupName(), (ArrayList<ProcessGroupConfig>) systemContext.getProcessGroupConfigs());
		
			//in the case of EUCA when DNS is not allowed, no public forwarder into TMS, IP addresses are used, verify default node has elastic IP assigned
			if("EUC".equals(config.getServiceProvider()) && config.getExternalDnsEnabled() == false){
				if("webapps.main".equals(processConfig.getProcessGroupName())){
					if("none".equals(userConfig.getPersistentIPAddress())){
						throw new ComposerException("DNS is not enabled for the system, an elastic IP is required to be allocated for the default process group, allocate an elastic IP to fix the error.");
					}
					else{
						this.properties.put("cas.service.rtws.default.webapp.host", userConfig.getPersistentIPAddress());
					}
				}
			}
			
			//need to refactor to remove process group after beta
			if("jms.external".equals(processConfig.getProcessGroupName()) || "jms.internal".equals(processConfig.getProcessGroupName())){
				//set values based on jms system sizing parameters from systemcontext
				userConfig.setInstanceSize(systemContext.getSystemSize().getJmsInstanceType());  //set instance type based on cluster size
				userConfig.setMaxCount(systemContext.getSystemSize().getJmsInstanceCount());
				userConfig.setMinCount(systemContext.getSystemSize().getJmsInstanceCount());
			}
			
			ProcessGroup process = createCommonNode(config, systemContext, processConfig, userConfig);
			
			//common to all webapps
			//set internet address if processgroup has on defined in systemContext
			if(processConfig.getPublicDomainName() != null && processConfig.getPublicDomainName().isEmpty() == false){
				process.getDefinition().setInternetAddress(processConfig.getPublicDomainName().replace("@build-domain@", config.getSystemDomain()));
				process.getDefinition().setAllocateInternetAddress(true);
			}
			
			//set webapps to install for process group from system context
			if(processConfig.getFixedWebapps() != null && processConfig.getFixedWebapps().isEmpty() == false){
				if("user".equals(processConfig.getFixedWebapps())){
					List<String> basic = new ArrayList<String>();
					List<String> plus = new ArrayList<String>();
					for(Webapp webapp : config.getWebapps()){
						if("basic".equals(webapp.getType())){
							basic.add(webapp.getFqn());
						}
						else if("plus".equals(webapp.getType())){
							plus.add(webapp.getFqn());
						}
						else{
							
						}
					}
					
					process.getDefinition().getProperties().put("RTWS_WEBAPP", createString(basic));
					process.getDefinition().getProperties().put("RTWS_WEBAPP_PLUS", createString(plus));
				}
				else{
					process.getDefinition().getProperties().put("RTWS_WEBAPP", createString(processConfig.getFixedWebapps()));
				}
			}
			
			//set scaling if turned on
			if(userConfig.getScaling()){
				String processName = userConfig.getProcessGroupName();
				
				InputStream is = null;
				//setup scaling using templates for ingest, marshall to object then add jms ollectors
				try{
					//check for choke template
					is = getClass().getResourceAsStream(String.format("%s/%s-choke.template.xml", baseDir, processName));
					if(is != null){
						JAXBElement<?> jaxbElement = serializer.createJAXBElement(is, JmsMemoryChoke.class);
						is.close();
						
						JmsMemoryChoke choke = (JmsMemoryChoke) jaxbElement.getValue();
						BoundsStatisticsCollector bCollector = (BoundsStatisticsCollector) choke.getStatisticsCollector();
						
						bCollector.setCollectors(createChokeJmxStatisticsCollectors(getConnectionUrlType(bCollector.getCollectors()), systemContext.getSystemSize().getJmsInstanceCount()));
						
						process.getAllocationPolicy().setChoke((JmsMemoryChoke) jaxbElement.getValue());
					}
					
					//check for scaling template
					is = getClass().getResourceAsStream(String.format("%s/%s-scaling.template.xml", baseDir, processName));
					
					// if this is a custom datasink, use the default scaling template if one is not already provided
					if (is == null && userConfig.getProcessGroupName().startsWith("datasink.")) {
						logger.info(String.format("Using default scaling template for custom datasink: %s", userConfig.getProcessGroupName()));
						is = getClass().getResourceAsStream(String.format("%s/%s-scaling.template.xml", baseDir, "datasink.custom"));
					}					
					if(is != null){
						Object jaxbObject = serializer.createObject(is);
						is.close();
						
						if(ThroughputScalingMonitor.class == ((JAXBElement<?>) jaxbObject).getValue().getClass()){
							ThroughputScalingMonitor scaling = (ThroughputScalingMonitor) ((JAXBElement<?>) jaxbObject).getValue();
							AggregatingStatisticsCollector collector = (AggregatingStatisticsCollector)scaling.getStatisticsCollector();
							
							if("ingest.all".equals(processName)){
								collector.setCollectors(createJmxStatisticsCollectors(getConnectionUrlType(collector.getCollectors()), systemContext.getSystemSize().getJmsInstanceCount(), 
												properties.getProperty(externalQueue), collector.getCollectors()));
							}
							else{
								
								collector.setCollectors(createJmxStatisticsCollectors(getConnectionUrlType(collector.getCollectors()), systemContext.getSystemSize().getJmsInstanceCount(), 
												SystemBuilderUtil.getQueueName(systemContext.getDataSinkConfigs(), processName), collector.getCollectors()));
							}
							
							process.getAllocationPolicy().setScalingMonitor(scaling);
							process.getAllocationPolicy().setAutoAllocationLag(240000);
							process.getAllocationPolicy().setAutoTerminationLag(60000);
							process.getAllocationPolicy().setAutoAllocationLimit(userConfig.getAllocationLimit());
							process.getAllocationPolicy().setAutoTerminationLimit(userConfig.getDeallocationLimit());
						}
						else if(ConsensusScalingMonitor.class == ((JAXBElement<?>) jaxbObject).getValue().getClass()){
							ConsensusScalingMonitor scaling = (ConsensusScalingMonitor) ((JAXBElement<?>) jaxbObject).getValue();
							for(ScalingMonitor monitor : scaling.getScalingMonitors()){
								//add jms collector configuration based on sizing
								if(monitor instanceof DiskUtilizationScalingMonitor){
									StatisticsCollector collector = ((DiskUtilizationScalingMonitor) monitor).getStatisticsCollector();
									
									if(collector instanceof RemoteJmxAggregatingStatisticsCollector){
										RemoteJmxAggregatingStatisticsCollector rsc = (RemoteJmxAggregatingStatisticsCollector) collector;
										rsc.setRemotePort(Integer.parseInt(properties.get("rtws.environment.jmx.port")));
										JmxNodeFinder nf = (JmxNodeFinder) rsc.getNodeFinder();
										nf.getJmxConnection().setJmxUrl(properties.get("master.jmx.url"));
									}
									else if(collector instanceof AggregatingStatisticsCollector){
										AggregatingStatisticsCollector asc = (AggregatingStatisticsCollector) collector;
										asc.setCollectors(createJmxStatisticsCollectors(getConnectionUrlType(asc.getCollectors()), systemContext.getSystemSize().getJmsInstanceCount(), 
																SystemBuilderUtil.getQueueName(systemContext.getDataSinkConfigs(), processName), asc.getCollectors()));
									}
									
									else{
										throw new ComposerException("Unknown StatisticsCollector type.");
									}
									
									
								}
								//add jms collector configuration based on sizing
								if(monitor instanceof ThroughputScalingMonitor){
									AggregatingStatisticsCollector collector = (AggregatingStatisticsCollector) ((ThroughputScalingMonitor) monitor).getStatisticsCollector();
									collector.setCollectors(createJmxStatisticsCollectors(getConnectionUrlType(collector.getCollectors()), systemContext.getSystemSize().getJmsInstanceCount(), 
											SystemBuilderUtil.getQueueName(systemContext.getDataSinkConfigs(), processName), collector.getCollectors()));
								}
							}
							
							process.getAllocationPolicy().setScalingMonitor(scaling);
							process.getAllocationPolicy().setAutoAllocationLag(240000);
							process.getAllocationPolicy().setAutoTerminationLag(60000);
							process.getAllocationPolicy().setAutoAllocationLimit(userConfig.getAllocationLimit());
							process.getAllocationPolicy().setAutoTerminationLimit(userConfig.getDeallocationLimit());
						}
						else{
							//unknown scaling type
						}
					}
				
				}catch(Exception e){
					e.printStackTrace();
					logger.error("No initializing scaling in configuration due to:  " + e.toString(), e);
					throw new ComposerException(e.toString(), e);
				}
				finally{
					try{
						if(is != null){
							is.close();
						}
					}catch(Exception e){logger.warn("Failed to close InputStream:  " + e.toString(), e);}
				}
			}
			
			clusterDefinition.addProcessGroup(process);  //add to template
		}
	}
	
	/**
	 * Create common process group configuration for each type of group.
	 * 
	 * @param config
	 * @param systemContext
	 * @param conf
	 * @param userProcessConfig
	 * @return
	 * @throws ComposerException 
	 */
	private ProcessGroup createCommonNode(SystemConfig config, SystemContext systemContext, ProcessGroupConfig conf, UserProcessGroupConfig userProcessConfig)
			throws ComposerException {
		//set common values/config for each process group do not duplicate or extract if it can be set in common
		ProcessGroup process = new ProcessGroup();
		process.setName(conf.getProcessGroupName());
		if(conf.getManagementInterfaces() != null){
			if(conf.getManagementInterfaces().contains(",")){
				process.setManagementInterfaces(conf.getManagementInterfaces().split(","));
			}
			else{
				String [] tmp = {conf.getManagementInterfaces()};
				process.setManagementInterfaces(tmp);
			}
		}
		
		//setup alloc policy
		ProcessAllocationPolicy policy = new ProcessAllocationPolicy();
		policy.setFqdn(conf.getInternalDomainName().replace("@build.domain@", config.getSystemDomain()));
		policy.setMax(userProcessConfig.getMaxCount());
		policy.setMin(userProcessConfig.getMinCount());
		process.setAllocationPolicy(policy);
		
		//set process definition
		ProcessDefinition definition = new ProcessDefinition();
		definition.setZone(config.getAvailZone());
		definition.setKey(config.getSshKey());
		definition.setVolumeCount(userProcessConfig.getVolumeCount());
		definition.setVolumeSize(userProcessConfig.getVolumeSize());
		//set instance type to user value, if null set to default value for process group type
		if(userProcessConfig.getInstanceSize() != null){
		definition.setType(userProcessConfig.getInstanceSize());
		}
		else{
			definition.setType(conf.getDefaultInstanceType());
		}
		
		if (config.getVpcEnabled()) {
			definition.setSecurity("vpc." + conf.getSecurityGroup());
		} else {
			definition.setSecurity(conf.getSecurityGroup());
		}
		
		//set persistent IP 
		if("none".equals(userProcessConfig.getPersistentIPAddress())){
			definition.setAllocatePersistentAddress(false);
		}
		else{
			definition.setAllocatePersistentAddress(true);
			definition.setPersistentIpAddress(userProcessConfig.getPersistentIPAddress());
		}
		
		definition.setImage(SystemBuilderUtil.getImageType((ArrayList<MachineImage>) systemContext.getMachineImages(), config.getServiceProvider(), 
												config.getRegion(), config.getSoftwareVersion(), (ArrayList<InstanceType>) systemContext.getInstanceTypes(), 
												conf.getInstanceStorage(), conf.getDefaultInstanceType(), tenantId));
		
		//common properties for all process groups
		Properties properties = new Properties();	
		properties.put("RTWS_MAX_ALLOCATION_REQUEST", "");
		properties.put("RTWS_MANIFEST", "/mnt/appfs/manifest/" + config.getSystemDomain() + "/" + conf.getManifestFilename());
		
		if(StringUtils.isNotEmpty(conf.getIngestConfigFilename()) == true){
			properties.put("RTWS_INGEST_CONFIG", conf.getIngestConfigFilename());
		}
		
		if(userProcessConfig.getVolumeCount() > 0){
			properties.put("RTWS_RAID_PATH", "/mnt/rdafs");
		}
		definition.setProperties(properties);
		
		//set vpc information if starting in vpc
		if (config.getVpcEnabled()) {
			definition.setSubnet(config.getSubnetId());
		}
		
		//set process definition
		process.setDefinition(definition);
		
		return process;
	}
	
	/**
	 * Creates a webapps property string value.
	 * 
	 * @param values
	 * @return
	 */
	private String createString(List<String> values){
		StringBuilder sb = new StringBuilder("");
		sb.append("\"");
		for(String value : values){
			sb.append(value.substring(value.lastIndexOf('.')+1, value.length()));
			sb.append(" ");
		}
		sb.append("\"");
		
		return sb.toString();
	}
	
	private String createString(String string){
		StringBuilder sb = new StringBuilder();
		sb.append("\"");
		sb.append(string);
		sb.append("\"");
		
		return sb.toString();
	}
	
	/**
	 * Creates scaling JMX collectors based on JMS cluster size.
	 * 
	 * @param propName JMX property to find url
	 * @param nodeCount int size of JMS cluster
	 * @param queueName String queue name
	 * @return
	 */
	private StatisticsCollector [] createJmxStatisticsCollectors(String propName, int nodeCount, String queueName, StatisticsCollector [] marshalledCollectors){
		StatisticsCollector [] tmp = null;
		
		if(propName.equals(filter)){
			tmp = new StatisticsCollector[marshalledCollectors.length];
			for(int i = 0; i < marshalledCollectors.length; i++){
				JmxStatisticsCollector jsc = new JmxStatisticsCollector();
				JmxConnection conn = new JmxConnection();
				conn.setJmxUrl(properties.filterProperty(((JmxStatisticsCollector)marshalledCollectors[i]).getJmxConnection().getJmxUrl()));
				conn.setObjectName(properties.filterProperty(((JmxStatisticsCollector)marshalledCollectors[i]).getJmxConnection().getObjectName()));
				jsc.setJmxConnection(conn);
				tmp[i] = jsc;
			}
		}
		else{
			tmp = new StatisticsCollector[nodeCount];
			for(int i = 1; i <= nodeCount; i++){
				JmxStatisticsCollector jsc = new JmxStatisticsCollector();
				JmxConnection conn = new JmxConnection();
				conn.setJmxUrl(properties.get(propName.replace("?", Integer.toString(i))));
				conn.setObjectName("org.apache.activemq:BrokerName=localhost,Type=Queue,Destination=?".replace("?", queueName));
				jsc.setJmxConnection(conn);
				tmp[i-1] = jsc;
			}
		}
		
		return tmp;
	}
	
	private String getConnectionUrlType(StatisticsCollector [] collectors) throws ComposerException{
		String propertyName = null;
		
		if(JmxStatisticsCollector.class == collectors[0].getClass()){
			if(((JmxStatisticsCollector) collectors[0]).getJmxConnection().getJmxUrl().contains("external")){
				propertyName = externalCollector;
			}
			else if(((JmxStatisticsCollector) collectors[0]).getJmxConnection().getJmxUrl().contains("internal")){
				propertyName = internalCollector;
			}
			else{
				propertyName = filter;
			}
		}
		else{
			throw new ComposerException("Unknown StatisticsCollector class type.");
		}
		
		return propertyName;
	}
	
	/**
	 * Creates scaling JMX colelctors based on JMS cluster size.
	 * 
	 * @param nodeCount
	 * @return
	 */
	private StatisticsCollector [] createChokeJmxStatisticsCollectors(String propName, int nodeCount){
		StatisticsCollector [] tmp = new StatisticsCollector[nodeCount];
		 
		for(int i = 1; i <= nodeCount; i++){
			JmxStatisticsCollector jsc = new JmxStatisticsCollector();
			JmxConnection conn = new JmxConnection();
			conn.setJmxUrl(properties.get(propName.replace("?", Integer.toString(i))));
			conn.setObjectName("org.apache.activemq:BrokerName=localhost,Type=Broker");
			jsc.setJmxConnection(conn);
			tmp[i-1] = jsc;
		}
		
		return tmp;
	}
	
	/**
	 * Set the tenant id.
	 * 
	 * @param tenantId String value
	 */
	public void setTenantId(String tenantId){
		this.tenantId = tenantId;
	}

}
