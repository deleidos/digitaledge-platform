#!/bin/bash
set -e

source /etc/rtwsrc

# Change link to hadoop configs
update-alternatives --install /etc/hadoop/conf hadoop-conf ${deb.install.prefix}/cluster 50
update-alternatives --set hadoop-conf ${deb.install.prefix}/cluster

ln -sf ${deb.install.prefix}/datanode-watchdog.sh /usr/local/bin/.

if [ ! -d /var/run/hadoop-hdfs ]; then
	mkdir -p /var/run/hadoop-hdfs ; chmod g+w /var/run/hadoop-hdfs
fi

cp -f ${deb.install.prefix}/${project.artifactId}-${project.version}-jmx-agent.jar /etc/hadoop/conf/jmx-agent.jar
chmod 444 /etc/hadoop/conf/jmx-agent.jar


perl -i -pe 's:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce:HADOOP_MAPRED_HOME=/usr/lib/hadoop-0.20-mapreduce:g' /etc/default/hadoop 

# Only add property if running on data node
if [[ "$RTWS_PROCESS_GROUP" == "hadoop.datanode" ]]; then
   export R_RTWS_FQDN=$RTWS_FQDN
   perl -i -pe 's:<!-- REPLACE_SLAVE_HOST_NAME -->:<property><name>slave.host.name</name><value>$ENV{R_RTWS_FQDN}</value></property>:g' /etc/hadoop/conf/mapred-site.xml

	# Correct user
	perl -i -pe 's:export HADOOP_IDENT_STRING=hadoop:export HADOOP_IDENT_STRING=mapred:g' /etc/default/hadoop-0.20-mapreduce-tasktracker
	perl -i -pe 's:export HADOOP_IDENT_STRING=hadoop:export HADOOP_IDENT_STRING=mapred:g' /etc/default/hadoop-0.20-mapreduce-jobtracker
fi

# Added for external usage as env is not inherited when custom jobs are submitted 
export R_DOMAIN=$RTWS_DOMAIN  # workaround for buggy env function below ???
export R_ZKSERVERS=$RTWS_ZOOKEEPER_QUORUM_SERVERS
perl -i -pe 's:\$\{RTWS_DOMAIN\}:$ENV{R_DOMAIN}:g' /etc/hadoop/conf/core-site.xml
perl -i -pe 's:\$\{RTWS_DOMAIN\}:$ENV{R_DOMAIN}:g' /etc/hadoop/conf/hdfs-site.xml
perl -i -pe 's:\$\{RTWS_DOMAIN\}:$ENV{R_DOMAIN}:g' /etc/hadoop/conf/mapred-site.xml
perl -i -pe 's:\$\{RTWS_ZOOKEEPER_QUORUM_SERVERS\}:$ENV{R_ZKSERVERS}:g' /etc/hbase/conf/hbase-site.xml
